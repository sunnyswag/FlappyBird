{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, action_dim = 1, state_dim, max_size, batch_size):\n",
    "        self.max_size = max_size\n",
    "        self.state_dim = state_dim\n",
    "        self.other_dim = action_dim + 1 + 1\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.state = np.empty((self.max_size, self.state_dim), dtype=np.float32)\n",
    "        self.other = np.empty((self.max_size, self.other_dim), dtype=np.float32)\n",
    "        self.size = 0\n",
    "        self.current_index = 0\n",
    "    \n",
    "    def store(self, state, action, reward, done):\n",
    "        self.state[self.current_index] = state\n",
    "        self.other[self.current_index] = [action, reward, done]\n",
    "        self.current_index = (self.current_index + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        ptr = np.random.choice(self.size, self.batch_size)\n",
    "        return (torch.FloatTensor(self.state[ptr]).to(self.device),\n",
    "                torch.FloatTensor(self.state[ptr + 1]).to(self.device),\n",
    "                    # TODO remove reshape\n",
    "                torch.LongTensor(self.other[ptr, 0:1].reshape(-1, 1)).to(self.device),\n",
    "                torch.FloatTensor(self.other[ptr, 1:2].reshape(-1, 1)).to(self.device),\n",
    "                torch.FloatTensor(self.other[ptr, 2:].reshape(-1, 1)).to(self.device))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, mid_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(state_dim, mid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mid_dim, mid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mid_dim, mid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mid_dim, action_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, state):\n",
    "        return self.network(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, mid_dim = 256, env_name):\n",
    "        self.learning_rate = 1e-4\n",
    "        self.explore_rate = 0.1\n",
    "        self.gamma = 0.99\n",
    "        self.target_update = 300\n",
    "        self.soft_update_tau = 5e-3\n",
    "        self.update_step = 300\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.env = gym.make(env_name)\n",
    "        self.state_dim = env.observation_space.shape[0]\n",
    "        self.mid_dim = mid_dim\n",
    "        self.action_dim = env.action_space.n\n",
    "        self.max_size = 100000\n",
    "        self.batch_size = 256\n",
    "        \n",
    "        self.network = QNetwork(self.state_dim, self.mid_dim, self.action_dim).to(self.device)\n",
    "        self.target_network = deepcopy(self.network)\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        \n",
    "        self.replay_buffer = ReplayBuffer(self.state_dim, self.max_size, self.batch_size)\n",
    "    \n",
    "    def epsilon(self, episode):\n",
    "        min_epsilon = 0.05\n",
    "        max_epsilon = 1\n",
    "        epsilon_decay = 800\n",
    "        epsilon_episode = lambda episode : min_epsilon + np.exp(-episode / epsilon_decay)*0.95\n",
    "        \n",
    "        return epsilon_episode\n",
    "        \n",
    "    def select_action(self, episode, state):\n",
    "        if np.random.random_sample() > epsilon(episode):\n",
    "            return self.network(torch.FloatTensor(state).to(self.device)).argmax().detach().cpu().numpy()\n",
    "        else:\n",
    "            return self.env.action_space.sample()\n",
    "    \n",
    "    def update(self):\n",
    "        for _ in range(self.update_step)\n",
    "            with torch.no_grad():\n",
    "                state, next_state, action, reward, done = self.replay_buffer.sample_batch()\n",
    "                next_Q = self.target_network(next_state).max(dim = 1, keepdim=True)[0]\n",
    "                target = reward + done * next_Q * self.gamma\n",
    "\n",
    "            current_Q = self.network(state).gather(1, action)\n",
    "            loss = self.criterion(current_Q, target)\n",
    "            \n",
    "            self.optimizer.zero_gard()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.soft_update(self.target_network, self.network, self.soft_update_tau)\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    @staticmethod\n",
    "    def soft_update(target_net, current_net, tau):\n",
    "        for tar, cur in zip(target_net.parameters(), current_net.parameters()):\n",
    "            tar.data.copy_(cur.data.__mul__(tau) + tar.data.__mul__(1 - tau))\n",
    "        \n",
    "    def load_model(self):\n",
    "        pass\n",
    "    \n",
    "    def save_model(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n"
     ]
    }
   ],
   "source": [
    "env_name = \"CartPole-v0\"\n",
    "env = gym.make(env_name)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n - 1\n",
    "# replay_buffer = ReplayBuffer()\n",
    "print(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
